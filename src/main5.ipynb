{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from ydata_profiling import ProfileReport\n",
    "from itertools import product\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# handling detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# imbalanced data \n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# hyper-parameter tunning\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import\\\n",
    "    accuracy_score, confusion_matrix, classification_report, \\\n",
    "    f1_score, recall_score, balanced_accuracy_score, precision_score, \\\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# storing the best model\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 30)  # Adjust the number as needed\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "train_data = pd.read_csv(\"../data/train.csv\").drop(columns=[\"id\"])\n",
    "train_data2 = pd.read_csv(\"../data/Cir.csv\").drop(columns=[\"ID\"]) # original data\n",
    "data = pd.concat(objs=[train_data, train_data2]).reset_index(drop=True) # combine 2 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform basic pipeline\n",
    "from src.pipelines import basic_pipeline\n",
    "\n",
    "# X_train = basic_pipeline.fit_transform(X_train)\n",
    "data = basic_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_years</th>\n",
       "      <th>Age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Status</th>\n",
       "      <th>took_drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.736986</td>\n",
       "      <td>58.991781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>179.80</td>\n",
       "      <td>63.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.052055</td>\n",
       "      <td>52.704110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>134.85</td>\n",
       "      <td>88.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.391781</td>\n",
       "      <td>37.608219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>3.3</td>\n",
       "      <td>299.0</td>\n",
       "      <td>3.55</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>119.35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.057534</td>\n",
       "      <td>50.575342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>256.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>71.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.158904</td>\n",
       "      <td>45.638356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.1</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>125.55</td>\n",
       "      <td>96.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>1.865753</td>\n",
       "      <td>67.046575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>3.021918</td>\n",
       "      <td>39.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320</th>\n",
       "      <td>2.890411</td>\n",
       "      <td>57.038356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>1.893151</td>\n",
       "      <td>58.041096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>2.673973</td>\n",
       "      <td>53.035616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>350.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8323 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       N_years        Age  is_male  Ascites  Hepatomegaly  Spiders Edema  \\\n",
       "0     2.736986  58.991781      1.0        0             0        0     N   \n",
       "1     7.052055  52.704110      0.0        0             0        0     N   \n",
       "2     9.391781  37.608219      0.0        0             1        1     Y   \n",
       "3     7.057534  50.575342      0.0        0             0        0     N   \n",
       "4     2.158904  45.638356      0.0        0             1        0     N   \n",
       "...        ...        ...      ...      ...           ...      ...   ...   \n",
       "8318  1.865753  67.046575      0.0        0             0        0     N   \n",
       "8319  3.021918  39.027397      0.0        0             0        0     N   \n",
       "8320  2.890411  57.038356      0.0        0             0        0     N   \n",
       "8321  1.893151  58.041096      0.0        0             0        0     N   \n",
       "8322  2.673973  53.035616      0.0        0             0        0     N   \n",
       "\n",
       "      Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "0           2.3        316.0     3.35   172.0    1601.0  179.80   \n",
       "1           0.9        364.0     3.54    63.0    1440.0  134.85   \n",
       "2           3.3        299.0     3.55   131.0    1029.0  119.35   \n",
       "3           0.6        256.0     3.50    58.0    1653.0   71.30   \n",
       "4           1.1        346.0     3.65    63.0    1181.0  125.55   \n",
       "...         ...          ...      ...     ...       ...     ...   \n",
       "8318        1.2          NaN     2.96     NaN       NaN     NaN   \n",
       "8319        0.9          NaN     3.83     NaN       NaN     NaN   \n",
       "8320        1.6          NaN     3.42     NaN       NaN     NaN   \n",
       "8321        0.8          NaN     3.75     NaN       NaN     NaN   \n",
       "8322        0.7          NaN     3.29     NaN       NaN     NaN   \n",
       "\n",
       "      Tryglicerides  Platelets  Prothrombin  Stage  Status  took_drug  \n",
       "0              63.0      394.0          9.7    3.0       2          1  \n",
       "1              88.0      361.0         11.0    3.0       0          0  \n",
       "2              50.0      199.0         11.7    4.0       2          0  \n",
       "3              96.0      269.0         10.7    3.0       0          0  \n",
       "4              96.0      298.0         10.6    4.0       0          0  \n",
       "...             ...        ...          ...    ...     ...        ...  \n",
       "8318            NaN      174.0         10.9    3.0       2          0  \n",
       "8319            NaN      180.0         11.2    4.0       0          0  \n",
       "8320            NaN      143.0          9.9    3.0       0          0  \n",
       "8321            NaN      269.0         10.4    3.0       0          0  \n",
       "8322            NaN      350.0         10.6    4.0       0          0  \n",
       "\n",
       "[8323 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.pipelines import *\n",
    "\n",
    "# advanced_pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\"missing_value_preprocess\", FunctionTransformer(func=missing_value_imputation, validate=False)),\n",
    "#         (\"outlier_removal_preprocess\", FunctionTransformer(func=outlier_removal_quantile, validate=False)),\n",
    "#         # (\"imbalanced_fix_preprocess\", FunctionTransformer(func=fix_imbalanced_SMOTE, validate=False)),\n",
    "#         (\"duplicate_removal_preprocess\", FunctionTransformer(func=duplicate_removal, validate=False)),\n",
    "#         (\"encoding_preprocess\", FunctionTransformer(func=encoding, validate=False)),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# advanced_pipeline.fit_transform(X_train)\n",
    "\n",
    "from src.pipelines import *\n",
    "\n",
    "advanced_pipeline = Pipeline(\n",
    "    [   \n",
    "        (\"missing_value_preprocess\", FunctionTransformer(func=missing_value_imputation, validate=False)),\n",
    "        (\"outlier_removal_preprocess\", FunctionTransformer(func=outlier_removal_quantile, validate=False)),\n",
    "        # (\"imbalanced_fix_preprocess\", FunctionTransformer(func=fix_imbalanced_SMOTE, validate=False)),\n",
    "        (\"duplicate_removal_preprocess\", FunctionTransformer(func=duplicate_removal, validate=False)),\n",
    "        (\"encoding_preprocess\", FunctionTransformer(func=encoding, validate=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data = advanced_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=[\"Status\"]), data[\"Status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian search using skopt\n",
    "np.int = np.int_ # fo fix the conflict with python version\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    xgb.XGBClassifier(),\n",
    "    {\n",
    "        \"n_estimators\": Integer(10, 100),\n",
    "        \"max_depth\": Integer(5, 50),\n",
    "        \"num_class\": Categorical([3]),\n",
    "        \"learning_rate\": Real(0.01, 0.4, prior=\"uniform\"),\n",
    "        \"booster\": Categorical([\"gbtree\", \"gblinear\"]),\n",
    "        # \"device\": Categorical([\"cuda\"]),\n",
    "        # \"tree_method\": Categorical([\"hist\"]),\n",
    "        # \"early_stopping_rounds\": Categorical([0, 5, 10, 20]),\n",
    "        \"eval_metric\":  [\"logloss\"], # mlogloss\n",
    "    },\n",
    "    n_iter=32,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    random_state=9090,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(final_data.drop(columns=[\"Status\"]), final_data[\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_years</th>\n",
       "      <th>Age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>took_drug</th>\n",
       "      <th>Edema_N</th>\n",
       "      <th>Edema_S</th>\n",
       "      <th>Edema_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>2.723288</td>\n",
       "      <td>40.819178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>291.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>227.04</td>\n",
       "      <td>106.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8.684932</td>\n",
       "      <td>58.210959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>478.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>75.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>97.65</td>\n",
       "      <td>108.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>4.021918</td>\n",
       "      <td>61.846575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>258.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>158.10</td>\n",
       "      <td>134.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>3.928767</td>\n",
       "      <td>56.608219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>212.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>41.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>127.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>4.849315</td>\n",
       "      <td>56.024658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>75.95</td>\n",
       "      <td>56.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       N_years        Age  is_male  Ascites  Hepatomegaly  Spiders  Bilirubin  \\\n",
       "6366  2.723288  40.819178      0.0        0             1        1        1.6   \n",
       "40    8.684932  58.210959      0.0        0             0        0        1.5   \n",
       "2814  4.021918  61.846575      0.0        0             0        0        2.1   \n",
       "1902  3.928767  56.608219      0.0        0             1        0        0.7   \n",
       "2057  4.849315  56.024658      0.0        0             1        1        1.6   \n",
       "\n",
       "      Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n",
       "6366        291.0     3.57    67.0    1601.0  227.04          106.0   \n",
       "40          478.0     3.43    75.0     289.0   97.65          108.0   \n",
       "2814        258.0     3.70    69.0    1214.0  158.10          134.0   \n",
       "1902        212.0     3.83    41.0     824.0  127.10           85.0   \n",
       "2057        226.0     3.35    39.0    1083.0   75.95           56.0   \n",
       "\n",
       "      Platelets  Prothrombin  Stage  took_drug  Edema_N  Edema_S  Edema_Y  \n",
       "6366      181.0         10.0    4.0          1        1        0        0  \n",
       "40        427.0          9.9    3.0          1        1        0        0  \n",
       "2814      225.0         12.0    2.0          0        1        0        0  \n",
       "1902      265.0         11.0    4.0          0        1        0        0  \n",
       "2057      336.0          9.7    3.0          1        1        0        0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.29609945082934797, max_depth=18, n_estimators=77, num_class=3;, score=0.840 total time=   1.6s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.29609945082934797, max_depth=18, n_estimators=77, num_class=3;, score=0.824 total time=   1.2s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.29609945082934797, max_depth=18, n_estimators=77, num_class=3;, score=0.852 total time=   1.1s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.29609945082934797, max_depth=18, n_estimators=77, num_class=3;, score=0.853 total time=   1.0s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.29609945082934797, max_depth=18, n_estimators=77, num_class=3;, score=0.818 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.17757114729954837, max_depth=14, n_estimators=54, num_class=3;, score=0.838 total time=   1.0s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.17757114729954837, max_depth=14, n_estimators=54, num_class=3;, score=0.816 total time=   0.8s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.17757114729954837, max_depth=14, n_estimators=54, num_class=3;, score=0.843 total time=   0.9s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.17757114729954837, max_depth=14, n_estimators=54, num_class=3;, score=0.848 total time=   1.0s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.17757114729954837, max_depth=14, n_estimators=54, num_class=3;, score=0.820 total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[11:44:07] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.01861369953945434, max_depth=14, n_estimators=94, num_class=3;, score=0.800 total time=   0.1s\n",
      "[11:44:07] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.01861369953945434, max_depth=14, n_estimators=94, num_class=3;, score=0.778 total time=   0.1s\n",
      "[11:44:07] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.01861369953945434, max_depth=14, n_estimators=94, num_class=3;, score=0.800 total time=   0.2s\n",
      "[11:44:07] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.01861369953945434, max_depth=14, n_estimators=94, num_class=3;, score=0.797 total time=   0.1s\n",
      "[11:44:07] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.01861369953945434, max_depth=14, n_estimators=94, num_class=3;, score=0.773 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3268872416877846, max_depth=16, n_estimators=25, num_class=3;, score=0.811 total time=   0.0s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3268872416877846, max_depth=16, n_estimators=25, num_class=3;, score=0.793 total time=   0.0s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3268872416877846, max_depth=16, n_estimators=25, num_class=3;, score=0.812 total time=   0.0s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3268872416877846, max_depth=16, n_estimators=25, num_class=3;, score=0.813 total time=   0.1s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3268872416877846, max_depth=16, n_estimators=25, num_class=3;, score=0.791 total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3240994439715655, max_depth=41, n_estimators=79, num_class=3;, score=0.813 total time=   0.1s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3240994439715655, max_depth=41, n_estimators=79, num_class=3;, score=0.792 total time=   0.1s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3240994439715655, max_depth=41, n_estimators=79, num_class=3;, score=0.820 total time=   0.1s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3240994439715655, max_depth=41, n_estimators=79, num_class=3;, score=0.825 total time=   0.1s\n",
      "[11:44:08] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.3240994439715655, max_depth=41, n_estimators=79, num_class=3;, score=0.798 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.08709524786390749, max_depth=8, n_estimators=97, num_class=3;, score=0.839 total time=   1.2s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.08709524786390749, max_depth=8, n_estimators=97, num_class=3;, score=0.824 total time=   1.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.08709524786390749, max_depth=8, n_estimators=97, num_class=3;, score=0.846 total time=   1.0s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.08709524786390749, max_depth=8, n_estimators=97, num_class=3;, score=0.850 total time=   1.2s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.08709524786390749, max_depth=8, n_estimators=97, num_class=3;, score=0.817 total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[11:44:14] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.37092079882544604, max_depth=46, n_estimators=87, num_class=3;, score=0.809 total time=   0.1s\n",
      "[11:44:14] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.37092079882544604, max_depth=46, n_estimators=87, num_class=3;, score=0.795 total time=   0.1s\n",
      "[11:44:14] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.37092079882544604, max_depth=46, n_estimators=87, num_class=3;, score=0.819 total time=   0.1s\n",
      "[11:44:14] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.37092079882544604, max_depth=46, n_estimators=87, num_class=3;, score=0.830 total time=   0.2s\n",
      "[11:44:14] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.37092079882544604, max_depth=46, n_estimators=87, num_class=3;, score=0.801 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2620089605384487, max_depth=37, n_estimators=46, num_class=3;, score=0.842 total time=   0.8s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2620089605384487, max_depth=37, n_estimators=46, num_class=3;, score=0.823 total time=   0.8s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2620089605384487, max_depth=37, n_estimators=46, num_class=3;, score=0.854 total time=   0.7s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2620089605384487, max_depth=37, n_estimators=46, num_class=3;, score=0.853 total time=   0.7s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2620089605384487, max_depth=37, n_estimators=46, num_class=3;, score=0.823 total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[11:44:18] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.12334447625170093, max_depth=25, n_estimators=21, num_class=3;, score=0.791 total time=   0.0s\n",
      "[11:44:18] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.12334447625170093, max_depth=25, n_estimators=21, num_class=3;, score=0.784 total time=   0.0s\n",
      "[11:44:18] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.12334447625170093, max_depth=25, n_estimators=21, num_class=3;, score=0.809 total time=   0.0s\n",
      "[11:44:18] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.12334447625170093, max_depth=25, n_estimators=21, num_class=3;, score=0.807 total time=   0.0s\n",
      "[11:44:18] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.12334447625170093, max_depth=25, n_estimators=21, num_class=3;, score=0.774 total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[11:44:19] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.36795012417401207, max_depth=48, n_estimators=46, num_class=3;, score=0.816 total time=   0.2s\n",
      "[11:44:19] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.36795012417401207, max_depth=48, n_estimators=46, num_class=3;, score=0.791 total time=   0.0s\n",
      "[11:44:19] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.36795012417401207, max_depth=48, n_estimators=46, num_class=3;, score=0.817 total time=   0.1s\n",
      "[11:44:19] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.36795012417401207, max_depth=48, n_estimators=46, num_class=3;, score=0.824 total time=   0.1s\n",
      "[11:44:19] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35t0jcmnzk/croot/xgboost-split_1712794695009/work/src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, eval_metric=logloss, learning_rate=0.36795012417401207, max_depth=48, n_estimators=46, num_class=3;, score=0.797 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=50, n_estimators=100, num_class=3;, score=0.842 total time=   1.2s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=50, n_estimators=100, num_class=3;, score=0.823 total time=   1.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=50, n_estimators=100, num_class=3;, score=0.843 total time=   1.5s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=50, n_estimators=100, num_class=3;, score=0.851 total time=   1.5s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=50, n_estimators=100, num_class=3;, score=0.826 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=5, n_estimators=10, num_class=3;, score=0.826 total time=   0.2s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=5, n_estimators=10, num_class=3;, score=0.825 total time=   0.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=5, n_estimators=10, num_class=3;, score=0.847 total time=   0.1s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=5, n_estimators=10, num_class=3;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.4, max_depth=5, n_estimators=10, num_class=3;, score=0.811 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.01, max_depth=50, n_estimators=10, num_class=3;, score=0.817 total time=   0.4s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.01, max_depth=50, n_estimators=10, num_class=3;, score=0.797 total time=   0.3s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.01, max_depth=50, n_estimators=10, num_class=3;, score=0.832 total time=   0.2s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.01, max_depth=50, n_estimators=10, num_class=3;, score=0.813 total time=   0.4s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.01, max_depth=50, n_estimators=10, num_class=3;, score=0.793 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.23966507911487103, max_depth=50, n_estimators=100, num_class=3;, score=0.844 total time=   2.6s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.23966507911487103, max_depth=50, n_estimators=100, num_class=3;, score=0.823 total time=   1.8s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.23966507911487103, max_depth=50, n_estimators=100, num_class=3;, score=0.851 total time=   1.4s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.23966507911487103, max_depth=50, n_estimators=100, num_class=3;, score=0.850 total time=   1.3s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.23966507911487103, max_depth=50, n_estimators=100, num_class=3;, score=0.824 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.011338392254873755, max_depth=45, n_estimators=99, num_class=3;, score=0.820 total time=   2.3s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.011338392254873755, max_depth=45, n_estimators=99, num_class=3;, score=0.800 total time=   2.2s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.011338392254873755, max_depth=45, n_estimators=99, num_class=3;, score=0.838 total time=   3.7s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.011338392254873755, max_depth=45, n_estimators=99, num_class=3;, score=0.831 total time=   5.1s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.011338392254873755, max_depth=45, n_estimators=99, num_class=3;, score=0.806 total time=   3.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3499221241552839, max_depth=50, n_estimators=10, num_class=3;, score=0.829 total time=   0.4s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3499221241552839, max_depth=50, n_estimators=10, num_class=3;, score=0.811 total time=   0.3s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3499221241552839, max_depth=50, n_estimators=10, num_class=3;, score=0.843 total time=   0.2s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3499221241552839, max_depth=50, n_estimators=10, num_class=3;, score=0.837 total time=   0.3s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3499221241552839, max_depth=50, n_estimators=10, num_class=3;, score=0.803 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3285985455261566, max_depth=5, n_estimators=100, num_class=3;, score=0.844 total time=   0.9s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3285985455261566, max_depth=5, n_estimators=100, num_class=3;, score=0.819 total time=   0.7s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3285985455261566, max_depth=5, n_estimators=100, num_class=3;, score=0.857 total time=   1.1s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3285985455261566, max_depth=5, n_estimators=100, num_class=3;, score=0.844 total time=   0.7s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3285985455261566, max_depth=5, n_estimators=100, num_class=3;, score=0.823 total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3931417900406008, max_depth=5, n_estimators=97, num_class=3;, score=0.838 total time=   0.9s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3931417900406008, max_depth=5, n_estimators=97, num_class=3;, score=0.825 total time=   0.6s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3931417900406008, max_depth=5, n_estimators=97, num_class=3;, score=0.851 total time=   0.7s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3931417900406008, max_depth=5, n_estimators=97, num_class=3;, score=0.835 total time=   0.5s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3931417900406008, max_depth=5, n_estimators=97, num_class=3;, score=0.825 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22719702439752215, max_depth=10, n_estimators=99, num_class=3;, score=0.844 total time=   1.5s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22719702439752215, max_depth=10, n_estimators=99, num_class=3;, score=0.815 total time=   1.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22719702439752215, max_depth=10, n_estimators=99, num_class=3;, score=0.854 total time=   1.1s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22719702439752215, max_depth=10, n_estimators=99, num_class=3;, score=0.850 total time=   1.1s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22719702439752215, max_depth=10, n_estimators=99, num_class=3;, score=0.825 total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.32988369013185886, max_depth=35, n_estimators=100, num_class=3;, score=0.839 total time=   1.6s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.32988369013185886, max_depth=35, n_estimators=100, num_class=3;, score=0.813 total time=   1.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.32988369013185886, max_depth=35, n_estimators=100, num_class=3;, score=0.847 total time=   1.6s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.32988369013185886, max_depth=35, n_estimators=100, num_class=3;, score=0.843 total time=   1.3s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.32988369013185886, max_depth=35, n_estimators=100, num_class=3;, score=0.816 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22277839105951858, max_depth=5, n_estimators=100, num_class=3;, score=0.843 total time=   0.8s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22277839105951858, max_depth=5, n_estimators=100, num_class=3;, score=0.819 total time=   0.5s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22277839105951858, max_depth=5, n_estimators=100, num_class=3;, score=0.846 total time=   0.5s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22277839105951858, max_depth=5, n_estimators=100, num_class=3;, score=0.835 total time=   0.5s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.22277839105951858, max_depth=5, n_estimators=100, num_class=3;, score=0.827 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19511501813731236, max_depth=25, n_estimators=10, num_class=3;, score=0.831 total time=   0.4s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19511501813731236, max_depth=25, n_estimators=10, num_class=3;, score=0.811 total time=   0.2s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19511501813731236, max_depth=25, n_estimators=10, num_class=3;, score=0.842 total time=   0.3s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19511501813731236, max_depth=25, n_estimators=10, num_class=3;, score=0.838 total time=   0.2s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19511501813731236, max_depth=25, n_estimators=10, num_class=3;, score=0.806 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3989990697052687, max_depth=12, n_estimators=99, num_class=3;, score=0.835 total time=   1.5s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3989990697052687, max_depth=12, n_estimators=99, num_class=3;, score=0.826 total time=   1.0s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3989990697052687, max_depth=12, n_estimators=99, num_class=3;, score=0.846 total time=   1.0s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3989990697052687, max_depth=12, n_estimators=99, num_class=3;, score=0.850 total time=   1.0s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3989990697052687, max_depth=12, n_estimators=99, num_class=3;, score=0.817 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19454570699990406, max_depth=47, n_estimators=100, num_class=3;, score=0.839 total time=   1.7s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19454570699990406, max_depth=47, n_estimators=100, num_class=3;, score=0.830 total time=   1.4s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19454570699990406, max_depth=47, n_estimators=100, num_class=3;, score=0.845 total time=   1.4s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19454570699990406, max_depth=47, n_estimators=100, num_class=3;, score=0.844 total time=   1.3s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.19454570699990406, max_depth=47, n_estimators=100, num_class=3;, score=0.823 total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39916776684875727, max_depth=49, n_estimators=99, num_class=3;, score=0.835 total time=   1.3s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39916776684875727, max_depth=49, n_estimators=99, num_class=3;, score=0.830 total time=   1.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39916776684875727, max_depth=49, n_estimators=99, num_class=3;, score=0.845 total time=   1.4s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39916776684875727, max_depth=49, n_estimators=99, num_class=3;, score=0.853 total time=   1.2s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39916776684875727, max_depth=49, n_estimators=99, num_class=3;, score=0.827 total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3996899776930465, max_depth=36, n_estimators=10, num_class=3;, score=0.835 total time=   0.4s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3996899776930465, max_depth=36, n_estimators=10, num_class=3;, score=0.829 total time=   0.3s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3996899776930465, max_depth=36, n_estimators=10, num_class=3;, score=0.839 total time=   0.2s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3996899776930465, max_depth=36, n_estimators=10, num_class=3;, score=0.839 total time=   0.2s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.3996899776930465, max_depth=36, n_estimators=10, num_class=3;, score=0.808 total time=   0.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.15150021258805463, max_depth=49, n_estimators=100, num_class=3;, score=0.837 total time=   1.7s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.15150021258805463, max_depth=49, n_estimators=100, num_class=3;, score=0.829 total time=   1.5s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.15150021258805463, max_depth=49, n_estimators=100, num_class=3;, score=0.852 total time=   1.7s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.15150021258805463, max_depth=49, n_estimators=100, num_class=3;, score=0.847 total time=   1.6s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.15150021258805463, max_depth=49, n_estimators=100, num_class=3;, score=0.821 total time=   1.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2520807112996348, max_depth=5, n_estimators=100, num_class=3;, score=0.845 total time=   0.8s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2520807112996348, max_depth=5, n_estimators=100, num_class=3;, score=0.827 total time=   0.6s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2520807112996348, max_depth=5, n_estimators=100, num_class=3;, score=0.851 total time=   0.5s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2520807112996348, max_depth=5, n_estimators=100, num_class=3;, score=0.838 total time=   0.5s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.2520807112996348, max_depth=5, n_estimators=100, num_class=3;, score=0.828 total time=   0.6s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39985046969008925, max_depth=46, n_estimators=98, num_class=3;, score=0.843 total time=   1.3s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39985046969008925, max_depth=46, n_estimators=98, num_class=3;, score=0.822 total time=   1.1s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39985046969008925, max_depth=46, n_estimators=98, num_class=3;, score=0.847 total time=   1.1s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39985046969008925, max_depth=46, n_estimators=98, num_class=3;, score=0.850 total time=   1.1s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39985046969008925, max_depth=46, n_estimators=98, num_class=3;, score=0.821 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.24813061596550912, max_depth=5, n_estimators=100, num_class=3;, score=0.838 total time=   0.8s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.24813061596550912, max_depth=5, n_estimators=100, num_class=3;, score=0.827 total time=   0.5s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.24813061596550912, max_depth=5, n_estimators=100, num_class=3;, score=0.852 total time=   0.6s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.24813061596550912, max_depth=5, n_estimators=100, num_class=3;, score=0.837 total time=   0.7s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.24813061596550912, max_depth=5, n_estimators=100, num_class=3;, score=0.826 total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.14545421839633096, max_depth=40, n_estimators=100, num_class=3;, score=0.840 total time=   1.8s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.14545421839633096, max_depth=40, n_estimators=100, num_class=3;, score=0.818 total time=   1.4s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.14545421839633096, max_depth=40, n_estimators=100, num_class=3;, score=0.846 total time=   1.5s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.14545421839633096, max_depth=40, n_estimators=100, num_class=3;, score=0.848 total time=   1.6s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.14545421839633096, max_depth=40, n_estimators=100, num_class=3;, score=0.820 total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39835925468150607, max_depth=19, n_estimators=58, num_class=3;, score=0.837 total time=   1.0s\n",
      "[CV 2/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39835925468150607, max_depth=19, n_estimators=58, num_class=3;, score=0.819 total time=   0.7s\n",
      "[CV 3/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39835925468150607, max_depth=19, n_estimators=58, num_class=3;, score=0.842 total time=   0.8s\n",
      "[CV 4/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39835925468150607, max_depth=19, n_estimators=58, num_class=3;, score=0.846 total time=   0.9s\n",
      "[CV 5/5] END booster=gbtree, eval_metric=logloss, learning_rate=0.39835925468150607, max_depth=19, n_estimators=58, num_class=3;, score=0.819 total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8388910036797361"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122271030090051"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
